{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd307fe",
   "metadata": {},
   "source": [
    "# AI Fall 00 - Hands-on - Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8e51c",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 16px\">\n",
    "<b>Paria Khoshtab 810198387</b>\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d8bf7b",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7694d20f",
   "metadata": {},
   "source": [
    "This project aims to get more familiar with `adversarial game trees` and `min-max algorithm`, which are used in the implementation of most `multi-agent` games. Also, we examine the impact of tree depth on agents' decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fda822",
   "metadata": {},
   "source": [
    "## Brief Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38fb011",
   "metadata": {},
   "source": [
    "In this problem, we have been given incomplete codes of the `Checkers` game, which involves diagonal moves of uniform game pieces and mandatory captures by jumping over opponent pieces. The goal of Checkers is to remove all your opponent's pieces from the board. To capture an opponent's piece and remove it from the board, you need to jump over their piece with one of yours. If, after jumping, your piece could make another jump, it is allowed to make an additional jump, which is called \"double-jumping.\" If one of your pieces gets to the opposite side of the board, \n",
    "it will turn into a King. Kings can move and jump diagonally in any direction. You win by removing your opponent's pieces from the board or if your opponent can't make a move.<br> What we need to do here is complete the incomplete codes that are\n",
    "related to the minimax algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de6ea6",
   "metadata": {},
   "source": [
    "## Modeling the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4c70f",
   "metadata": {},
   "source": [
    "The state space of this problem consists of states, including information about the board (position of pieces).<br>\n",
    "- <b>Initial state</b>: initial board game, including 24 pieces<br>\n",
    "- <b>Players</b>: P = {1, 2}<br>\n",
    "- <b>Actions</b>: 1) diagonal move 2) removing opponent's pieces from the board by jumping over them<br>\n",
    "- <b>Terminal state</b>: removing all of opponent's pieces from the board<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1ca00",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54192db3",
   "metadata": {},
   "source": [
    "First, we have to implement the `getValidMoves` function using the `_traverseLeft` and `_traverseRight` functions.<br>\n",
    "This function returns all the valid moves that a piece can make.<br>\n",
    "As we can see below, king pieces can move and jump in 4 directions, but non-king pieces can move and jump in only two directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aea090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidMoves(self, piece):\n",
    "    valid_moves = {}\n",
    "\n",
    "    if piece.king:\n",
    "        valid_moves.update(self._traverseLeft(piece.row - 1, max(-1, piece.row - 3), -1, piece.color, piece.col - 1))\n",
    "        valid_moves.update(self._traverseRight(piece.row - 1, max(-1, piece.row - 3), -1, piece.color, piece.col + 1))\n",
    "        valid_moves.update(self._traverseLeft(piece.row + 1, min(ROWS, piece.row + 3), +1, piece.color, piece.col - 1))\n",
    "        valid_moves.update(self._traverseRight(piece.row + 1, min(ROWS, piece.row + 3), +1, piece.color, piece.col + 1))\n",
    "    elif piece.color == RED:\n",
    "        valid_moves.update(self._traverseLeft(piece.row - 1, max(-1, piece.row - 3), -1, piece.color, piece.col - 1))\n",
    "        valid_moves.update(self._traverseRight(piece.row - 1, max(-1, piece.row - 3), -1, piece.color, piece.col + 1))\n",
    "    elif piece.color == WHITE:\n",
    "        valid_moves.update(self._traverseLeft(piece.row + 1, min(ROWS, piece.row + 3), +1, piece.color, piece.col - 1))\n",
    "        valid_moves.update(self._traverseRight(piece.row + 1, min(ROWS, piece.row + 3), +1, piece.color, piece.col + 1))\n",
    "\n",
    "    return valid_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd97232",
   "metadata": {},
   "source": [
    "The `simulateMove` function takes a piece, destination position (move), the board, and skipped pieces as parameters in order to\n",
    "simulate a move of a piece and remove skipped pieces from the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e519e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulateMove(piece, move, board, skip):\n",
    "    board.remove(skip)\n",
    "    board.move(piece, move[0], move[1])\n",
    "    return board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0fe34",
   "metadata": {},
   "source": [
    "The `getAllMoves` function takes color and the board as parameters in order to return all the successor states (boards) of the \n",
    "current state(board) based on its color, using `getValidMoves` and `simulateMove` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29339c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllMoves(board, color):\n",
    "    boards = []\n",
    "    for piece in board.getAllPieces(color):\n",
    "        for move, skipped in board.getValidMoves(piece).items():\n",
    "            newBoard = deepcopy(board)\n",
    "            newBoard = simulateMove(newBoard.getPiece(piece.row, piece.col), move, newBoard, skipped)\n",
    "            boards.append(newBoard)\n",
    "    return boards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac937a74",
   "metadata": {},
   "source": [
    "`minimax` **depth-limited** function returns the next optimal move for a player and the minimax value (evaluation) of the selected state,\n",
    "assuming that your opponent also plays optimally.<br>\n",
    "We need to implement a function that estimates the value or goodness of the board depending on the placement of pieces\n",
    "on the board in minimax, typically a weighted linear sum of features.\n",
    "This function is often known as the **Evaluation Function**. The ideal evaluation function\n",
    "returns the actual minimax value of the state.\n",
    "The evaluation function is unique for every type of game.<br>\n",
    "We compute minimax value (evaluation) of state \"s\" as follows:<br>\n",
    "Terminal states(states with given depth): V(s) = evaluate(s)<br>\n",
    "States under opponent's control: V(s) = min V(s') ; s' is a member of successors(s)<br>\n",
    "States under agent's control: V(s) = max V(s') ; s' is a member of successors(s)<br>\n",
    "Based on the descriptions above, we implement the `minimax` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab795ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(position, depth, maxPlayer):\n",
    "    if depth == 0:\n",
    "        return position.evaluate(), position\n",
    "\n",
    "    value = None\n",
    "    newBoard = deepcopy(position)\n",
    "\n",
    "    if maxPlayer == True:\n",
    "        value = -math.inf\n",
    "        for board in getAllMoves(position, WHITE):\n",
    "            newValue = minimax(board, depth - 1, False)[0]\n",
    "            if newValue >= value:\n",
    "                value = newValue\n",
    "                newBoard = deepcopy(board)\n",
    "\n",
    "    elif maxPlayer == False:\n",
    "        value = math.inf\n",
    "        for board in getAllMoves(position, RED):\n",
    "            newValue = minimax(board, depth - 1, True)[0]\n",
    "            if newValue <= value:\n",
    "                value = newValue\n",
    "                newBoard = deepcopy(board)\n",
    "\n",
    "    return value, newBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d176d58",
   "metadata": {},
   "source": [
    "## Examining the Algorithm with Different Depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af1e21",
   "metadata": {},
   "source": [
    "* Note that the analysis of the below tests is what we expect, \n",
    "but in reality, our game gets stuck in a local answer and falls into a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982aec65",
   "metadata": {},
   "source": [
    "#### Test # 1: Low Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ea9d0",
   "metadata": {},
   "source": [
    "If we consider a depth 1 for both players, the algorithm gets very fast at the expense of optimality. \n",
    "The algorithm's speed improves a lot, but players do not necessarily make the best decisions by searching the whole tree because they can not predict many moves. So, there is no guarantee that either the RED player or the WHITE player will win the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47abdc8",
   "metadata": {},
   "source": [
    "#### Test # 2 High Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9bdbe1",
   "metadata": {},
   "source": [
    "If we consider depth 5 for the RED player and depth 2 for the WHITE player, the algorithm gets slower than the previous test, but since the RED player examines more depth of the tree, its evaluation function becomes more accurate, resulting in better decisions than the WHITE player takes. So, the RED player is more likely to win the game than the WHITE player."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd9532",
   "metadata": {},
   "source": [
    "#### Test # 3 Equal Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d0a20f",
   "metadata": {},
   "source": [
    "If we consider depth 5 for both players, the algorithm gets slower than the previous two tests, but since both players \n",
    "examine more depth of the tree and can predict more moves, their evaluation functions become more accurate,\n",
    "resulting in better decisions, so both players make better and more optimal decisions than Test 1 with low depth. \n",
    "Thus, the probability of the RED player winning the game increases as the probability of winning the WHITE player increases, \n",
    "but I guess the player who starts the game has a better chance of winning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17534737",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41fa16",
   "metadata": {},
   "source": [
    "The Minimax algorithm takes into account all the possible moves that players can take at any given time during the game.\n",
    "This enables the algorithm to minimize the opponent’s advantage while simultaneously maximizing the agent’s advantage\n",
    "at every turn.\n",
    "Though effective in finding accurate solutions in simple games, the minimax algorithm is not the best choice for\n",
    "games with exceptionally high branching factors. To improve this drawback, Alpha Beta Pruning is implemented\n",
    "in the Minimax Algorithm.\n",
    "Alpha Beta Pruning seeks to decrease the number of nodes that are evaluated by the minimax algorithm\n",
    "by passing two extra parameters, Alpha and Beta.<br>\n",
    "Additionally, evaluation functions are always imperfect, but the deeper in the tree the evaluation function is buried,\n",
    "the less the quality of the evaluation function matters. There is always a trade-off between the optimality of decisions made by\n",
    "the evaluation function and the cost(time) of the minimax algorithm. By defining a good evaluation function, we make better\n",
    "decisions in order to get close to the optimal decisions and reach the goal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
